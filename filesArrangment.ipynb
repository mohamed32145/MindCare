{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLguGwfxK/sNMFM3rKY2KF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamed32145/MindCare/blob/main/filesArrangment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQHAAWA0tsAm"
      },
      "outputs": [],
      "source": [
        "\"\"\" we will authenticate colab to access to our data on google drive to start organize and\n",
        " prepare the images fodlers\n",
        "\n",
        " \"\"\"\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Step 3: Authenticate and create PyDrive2 client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "first step was to orginaze the data to :\n",
        "\n",
        "CN (Cognitively Normal)\n",
        "sMCI (Stable MCI)\n",
        "pMCI (Progressive MCI)\n",
        "AD (Alzheimer's Disease)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "then we will delete the files labeled with *_scaled_2* because those file containes images\n",
        "that have been adjusted to disable scaling on axes where the phantom's measurements are considered unreliable.\n",
        "although *_scaled_2* are more accurate but they are less than the *_scaled* files by far and cant be mixed with the _scsale\n",
        "images for the traning session\n",
        " \"\"\"\n",
        "\n",
        "#a reusable function that search and delete the scaled_2 file in the all groups (AD, CN, pMCI, sMCI)\n",
        "\n",
        "def delete_scaled_2_folders_in_group(parent_folder_id, group_name):\n",
        "    print(f\"\\ Processing group: {group_name}\")\n",
        "\n",
        "    # Get all subject folders inside the parent group folder (e.g., AD)\n",
        "    subject_folders = drive.ListFile({\n",
        "        'q': f\"'{parent_folder_id}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
        "    }).GetList()\n",
        "\n",
        "    for subject in subject_folders:\n",
        "        print(f\" Checking subject: {subject['title']}\")\n",
        "\n",
        "        # Get subfolders inside each subject folder\n",
        "        subfolders = drive.ListFile({\n",
        "            'q': f\"'{subject['id']}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
        "        }).GetList()\n",
        "\n",
        "        for folder in subfolders:\n",
        "            if folder['title'].endswith('Scaled_2'):\n",
        "                print(f\" Deleting folder: {folder['title']} in subject {subject['title']}\")\n",
        "                folder.Delete()\n",
        "\n",
        "\n",
        "AD_FOLDER_ID = '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU'\n",
        "CN_FOLDER_ID = '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU'\n",
        "PMCI_FOLDER_ID = '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU'\n",
        "SMCI_FOLDER_ID = '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU'\n",
        "\n",
        "# Call the function for each group\n",
        "delete_scaled_2_folders_in_group(AD_FOLDER_ID, 'AD')\n",
        "delete_scaled_2_folders_in_group(CN_FOLDER_ID, 'CN')\n",
        "delete_scaled_2_folders_in_group(PMCI_FOLDER_ID, 'pMCI')\n",
        "delete_scaled_2_folders_in_group(SMCI_FOLDER_ID, 'sMCI')\n"
      ],
      "metadata": {
        "id": "Zozwfm4quB8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "now we consider the case where a subject has two kinds of scanning sessions one\n",
        "(two fodlers) one starting with MPR and the other MPR-R .MPR probably stands for \"Multiplanar Reconstruction,\n",
        "\" a technique that generates images in multiple planes (e.g., axial, sagittal, coronal) from a single acquisition.\n",
        "MPR-R may indicate a refined or revised version of the MPR protocol, potentially with improved quality or specific\n",
        "modifications for certain research purposes\n",
        "\n",
        "MPR-R is less by far than MPR, some subjects has MPR-R images more than the MPR\n",
        "images, just in this case we will choose the MPR-R images\n",
        "\n",
        "MPR-R and MPR can be mixes for the training session considering the images will\n",
        "go through Preprocessing  like:\n",
        "\n",
        "Skull Stripping\n",
        "\n",
        "Bias Field Correction\n",
        "\n",
        "Resampling to Common Resolution\n",
        "\n",
        "Intensity Normalization\n",
        "\n",
        "which we will do for all the iamges\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def clean_mpr_vs_mprr(drive_folder_id):\n",
        "    subject_folders = drive.ListFile({'q': f\"'{drive_folder_id}' in parents and trashed=false\"}).GetList()\n",
        "\n",
        "    for subject in subject_folders:\n",
        "        if subject['mimeType'] != 'application/vnd.google-apps.folder':\n",
        "            continue\n",
        "\n",
        "        subject_id = subject['id']\n",
        "        subject_name = subject['title']\n",
        "        print(f\"\\n🔍 Checking subject: {subject_name}\")\n",
        "\n",
        "        subfolders = drive.ListFile({'q': f\"'{subject_id}' in parents and trashed=false\"}).GetList()\n",
        "\n",
        "        mpr_folder = None\n",
        "        mprr_folder = None\n",
        "        mpr_count = 0\n",
        "        mprr_count = 0\n",
        "\n",
        "        for f in subfolders:\n",
        "            name = f['title']\n",
        "            if f['mimeType'] != 'application/vnd.google-apps.folder':\n",
        "                continue\n",
        "\n",
        "            if name.startswith('MPR__') and not name.startswith('MPR-R__'):\n",
        "                contents = drive.ListFile({'q': f\"'{f['id']}' in parents and trashed=false\"}).GetList()\n",
        "                mpr_folder = f\n",
        "                mpr_count = len(contents)\n",
        "\n",
        "            elif name.startswith('MPR-R__'):\n",
        "                contents = drive.ListFile({'q': f\"'{f['id']}' in parents and trashed=false\"}).GetList()\n",
        "                mprr_folder = f\n",
        "                mprr_count = len(contents)\n",
        "\n",
        "        if mpr_folder and mprr_folder:\n",
        "            print(f\" MPR: {mpr_count} files, MPR-R: {mprr_count} files\")\n",
        "\n",
        "            # Prefer MPR-R if same or more files\n",
        "            if mprr_count >= mpr_count:\n",
        "                print(\" Deleting MPR\")\n",
        "                drive.CreateFile({'id': mpr_folder['id']}).Trash()\n",
        "            else:\n",
        "                print(\" Deleting MPR-R\")\n",
        "                drive.CreateFile({'id': mprr_folder['id']}).Trash()\n",
        "        else:\n",
        "            print(\" One or both MPR versions not found.\")\n",
        "\n",
        "\n",
        "\n",
        "folder_ids = {\n",
        "    'AD': '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU',\n",
        "    'PMCI': '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU',\n",
        "    'sMCI': '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU',\n",
        "    'CN': '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU''\n",
        "}\n",
        "\n",
        "for name, folder_id in folder_ids.items():\n",
        "    print(f\"\\n Processing: {name}\")\n",
        "    clean_mpr_vs_mprr(folder_id)\n",
        "\n"
      ],
      "metadata": {
        "id": "djDdDlH9uRGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "as we want to train and deploy a longitudinal deep learning model its important\n",
        "to orginaze the data so it would be consistent with the model structure\n",
        "\n",
        "so we turn such .nii file path from\n",
        "\"ADNI\\AD\\002_S_0619\\MPR-R__GradWarp__N3__Scaled\\2007-06-22_07_06_17.0\\I67871\\ADNI_002_S_0619_MR_MPR-R__GradWarp__N3__Scaled_Br_20070816100717385_S33969_I67871.nii\"\n",
        " into this\n",
        "\"ADNI_Organized\\AD\\002_S_0619\\timepoint_1\\ADNI_002_S_0619_MR_MPR-R__GradWarp__N3__Scaled_Br_20070816100717385_S33969_I67871.nii\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Load the metadata CSV\n",
        "metadata_path = \"https://drive.google.com/drive/folders/1yD7Yv-Gn0HluP3yAkhLuUFZn_Savy-Xh?usp=drive_link\"  # or your actual path\n",
        "df = pd.read_csv(metadata_path)\n",
        "\n",
        "# Define output root directory\n",
        "output_root = \"C:/ADNI_Organized\"\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    group = row['group']\n",
        "    subject_id = row['subject_id']\n",
        "    timepoint = row['timepoint']\n",
        "    original_path = row['original_path']\n",
        "\n",
        "    # Target path\n",
        "    target_dir = os.path.join(output_root, group, subject_id, f\"timepoint_{timepoint}\")\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "    # Copy the file\n",
        "    try:\n",
        "        shutil.copy(original_path, target_dir)\n",
        "        print(f\" Copied: {original_path} ➜ {target_dir}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\" File not found: {original_path}\")\n"
      ],
      "metadata": {
        "id": "GD-TpLadupf5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}