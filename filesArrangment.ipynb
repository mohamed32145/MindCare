{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyLdF/YCbuGRE4As3BnXMW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamed32145/MindCare/blob/main/filesArrangment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQHAAWA0tsAm"
      },
      "outputs": [],
      "source": [
        "\"\"\" we will authenticate colab to access to our data on google drive to start organize and\n",
        " prepare the images fodlers\n",
        "\n",
        " \"\"\"\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Step 3: Authenticate and create PyDrive2 client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "---\n",
        "\n",
        "**Step 1: Data Organization**\n",
        "\n",
        "The dataset was first organized into the following diagnostic groups:\n",
        "\n",
        "* **CN** (Cognitively Normal)\n",
        "* **sMCI** (Stable Mild Cognitive Impairment)\n",
        "* **pMCI** (Progressive Mild Cognitive Impairment)\n",
        "* **AD** (Alzheimer‚Äôs Disease)\n",
        "\n",
        "---\n",
        "\n",
        " Image Selection Criteria\n",
        "\n",
        " For the AD and CN groups:\n",
        "\n",
        "* We retained only the images with the following preprocessing pipeline:\n",
        "  `MPR-R__GradWarp__B1_Correction__N3__Scaled` or\n",
        "  `MPR__GradWarp__B1_Correction__N3__Scaled`.\n",
        "\n",
        "* Images labeled with `*_scaled_2*` were removed.\n",
        "  These images were adjusted to disable scaling on axes where the phantom's measurements are considered unreliable.\n",
        "  While `*_scaled_2*` images may offer higher accuracy, they are significantly fewer in number and **cannot be mixed** with the standard `*_scaled*` images for model training due to consistency issues.\n",
        "\n",
        "---\n",
        "\n",
        " For the sMCI and pMCI groups:\n",
        "\n",
        "* Due to the limited availability of subjects in these groups, we included:\n",
        "\n",
        "  * `MPR-R__GradWarp__B1_Correction__N3__Scaled`\n",
        "  * `MPR__GradWarp__B1_Correction__N3__Scaled`\n",
        "  * `MPR__GradWarp__N3__Scaled`\n",
        "\n",
        "* Subjects with only `MPR__GradWarp__N3__Scaled` images will undergo additional preprocessing, specifically:\n",
        "\n",
        "  *Bias field correction, to reduce intensity non-uniformity and improve image quality before training.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \"\"\"\n",
        "\n",
        "#a reusable function that search and delete the scaled_2 file in the all groups (AD, CN, pMCI, sMCI)\n",
        "\n",
        "def delete_scaled_2_folders_in_group(parent_folder_id, group_name):\n",
        "    print(f\"\\ Processing group: {group_name}\")\n",
        "\n",
        "    # Get all subject folders inside the parent group folder (e.g., AD)\n",
        "    subject_folders = drive.ListFile({\n",
        "        'q': f\"'{parent_folder_id}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
        "    }).GetList()\n",
        "\n",
        "    for subject in subject_folders:\n",
        "        print(f\" Checking subject: {subject['title']}\")\n",
        "\n",
        "        # Get subfolders inside each subject folder\n",
        "        subfolders = drive.ListFile({\n",
        "            'q': f\"'{subject['id']}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
        "        }).GetList()\n",
        "\n",
        "        for folder in subfolders:\n",
        "            if folder['title'].endswith('Scaled_2'):\n",
        "                print(f\" Deleting folder: {folder['title']} in subject {subject['title']}\")\n",
        "                folder.Delete()\n",
        "\n",
        "\n",
        "AD_FOLDER_ID = '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU'\n",
        "CN_FOLDER_ID = '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU'\n",
        "PMCI_FOLDER_ID = '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU'\n",
        "SMCI_FOLDER_ID = '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU'\n",
        "\n",
        "# Call the function for each group\n",
        "delete_scaled_2_folders_in_group(AD_FOLDER_ID, 'AD')\n",
        "delete_scaled_2_folders_in_group(CN_FOLDER_ID, 'CN')\n",
        "delete_scaled_2_folders_in_group(PMCI_FOLDER_ID, 'pMCI')\n",
        "delete_scaled_2_folders_in_group(SMCI_FOLDER_ID, 'sMCI')\n"
      ],
      "metadata": {
        "id": "Zozwfm4quB8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "now we consider the case where a subject has two kinds of scanning sessions one\n",
        "(two fodlers) one starting with MPR and the other MPR-R .MPR probably stands for \"Multiplanar Reconstruction,\n",
        "\" a technique that generates images in multiple planes (e.g., axial, sagittal, coronal) from a single acquisition.\n",
        "MPR-R may indicate a refined or revised version of the MPR protocol, potentially with improved quality or specific\n",
        "modifications for certain research purposes\n",
        "\n",
        "MPR-R is less by far than MPR, some subjects has MPR-R images more than the MPR\n",
        "images, just in this case we will choose the MPR-R images\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#we run this function on all the folders\n",
        "def clean_mpr_vs_mprr(drive_folder_id):\n",
        "    subject_folders = drive.ListFile({'q': f\"'{drive_folder_id}' in parents and trashed=false\"}).GetList()\n",
        "\n",
        "    for subject in subject_folders:\n",
        "        if subject['mimeType'] != 'application/vnd.google-apps.folder':\n",
        "            continue\n",
        "\n",
        "        subject_id = subject['id']\n",
        "        subject_name = subject['title']\n",
        "        print(f\"\\n Checking subject: {subject_name}\")\n",
        "\n",
        "        subfolders = drive.ListFile({'q': f\"'{subject_id}' in parents and trashed=false\"}).GetList()\n",
        "\n",
        "        mpr_folder = None\n",
        "        mprr_folder = None\n",
        "        mpr_count = 0\n",
        "        mprr_count = 0\n",
        "\n",
        "        for f in subfolders:\n",
        "            name = f['title']\n",
        "            if f['mimeType'] != 'application/vnd.google-apps.folder':\n",
        "                continue\n",
        "\n",
        "            if name.startswith('MPR__') and not name.startswith('MPR-R__'):\n",
        "                contents = drive.ListFile({'q': f\"'{f['id']}' in parents and trashed=false\"}).GetList()\n",
        "                mpr_folder = f\n",
        "                mpr_count = len(contents)\n",
        "\n",
        "            elif name.startswith('MPR-R__'):\n",
        "                contents = drive.ListFile({'q': f\"'{f['id']}' in parents and trashed=false\"}).GetList()\n",
        "                mprr_folder = f\n",
        "                mprr_count = len(contents)\n",
        "\n",
        "        if mpr_folder and mprr_folder:\n",
        "            print(f\" MPR: {mpr_count} files, MPR-R: {mprr_count} files\")\n",
        "\n",
        "            # Prefer MPR-R if same or more files\n",
        "            if mprr_count >= mpr_count:\n",
        "                print(\" Deleting MPR\")\n",
        "                drive.CreateFile({'id': mpr_folder['id']}).Trash()\n",
        "            else:\n",
        "                print(\" Deleting MPR-R\")\n",
        "                drive.CreateFile({'id': mprr_folder['id']}).Trash()\n",
        "        else:\n",
        "            print(\" One or both MPR versions not found.\")\n",
        "\n",
        "\n",
        "\n",
        "folder_ids = {\n",
        "    'AD': '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU',\n",
        "    'PMCI': '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU',\n",
        "    'sMCI': '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU',\n",
        "    'CN': '1OwQEPuyEC12DA9BOTHxC_9OJGoRgWYOU''\n",
        "}\n",
        "\n",
        "for name, folder_id in folder_ids.items():\n",
        "    print(f\"\\n Processing: {name}\")\n",
        "    clean_mpr_vs_mprr(folder_id)\n",
        "\n"
      ],
      "metadata": {
        "id": "djDdDlH9uRGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "the above function keep files such MPR__GradWarp__N3__Scaled in all the folder\n",
        "for the AN, CN  groups we dont need them for cause the images availbility\n",
        "so we will delete them\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def clean_subjects_with_mpr(root_dirs):\n",
        "    keep_folders = {\n",
        "        \"MPR__GradWarp__B1_Correction__N3__Scaled\",\n",
        "        \"MPR-R__GradWarp__B1_Correction__N3__Scaled\"\n",
        "    }\n",
        "\n",
        "    for root_dir in root_dirs:\n",
        "        print(f\"\\n Scanning root directory: {root_dir}\")\n",
        "        for subject_id in os.listdir(root_dir):\n",
        "            subject_path = os.path.join(root_dir, subject_id)\n",
        "            if not os.path.isdir(subject_path):\n",
        "                continue\n",
        "\n",
        "            # Check if the subject contains any of the desired folders\n",
        "            subfolders = os.listdir(subject_path)\n",
        "            has_valid_mpr = any(folder in keep_folders for folder in subfolders)\n",
        "\n",
        "            if not has_valid_mpr:\n",
        "                print(f\" Deleting subject (no valid MPR): {subject_path}\")\n",
        "                shutil.rmtree(subject_path)\n",
        "            else:\n",
        "                print(f\" Keeping subject: {subject_path}\")\n",
        "\n",
        "# Example usage:\n",
        "clean_subjects_with_mpr([\n",
        "    r\"C:\\ADNI\\AD\",\n",
        "    r\"C:\\ADNI\\CN\"\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "3EOTKMoQ_F8p",
        "outputId": "50f49543-16d1-4c4c-976d-4930fa3260a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Scanning root directory: C:\\ADNI\\AD\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\ADNI\\\\AD'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-602a419049f6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m clean_subjects_with_mpr([\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;34mr\"C:\\ADNI\\AD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;34mr\"C:\\ADNI\\CN\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-602a419049f6>\u001b[0m in \u001b[0;36mclean_subjects_with_mpr\u001b[0;34m(root_dirs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mroot_dirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n Scanning root directory: {root_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubject_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0msubject_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\ADNI\\\\AD'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "now for the pMCI , sMCI groups we will keep the MPR-R/MPR__GradWarp__B1_Correction__N3__Scaled\n",
        "and the  MPR__GradWarp__N3__Scaled we be saved in a new subfolder to be bias corrected later\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def process_subjects_for_mpr(root_dirs):\n",
        "    keep_folders = {\n",
        "        \"MPR__GradWarp__B1_Correction__N3__Scaled\",\n",
        "        \"MPR-R__GradWarp__B1_Correction__N3__Scaled\"\n",
        "    }\n",
        "    preprocess_folder = \"NeedsPreprocessing\"\n",
        "    n3_folder = \"MPR__GradWarp__N3__Scaled\"\n",
        "\n",
        "    for root_dir in root_dirs:\n",
        "        print(f\"\\n Processing root: {root_dir}\")\n",
        "        for subject_id in os.listdir(root_dir):\n",
        "            subject_path = os.path.join(root_dir, subject_id)\n",
        "            if not os.path.isdir(subject_path):\n",
        "                continue\n",
        "\n",
        "            subfolders = os.listdir(subject_path)\n",
        "            has_b1 = any(folder in keep_folders for folder in subfolders)\n",
        "            has_n3 = n3_folder in subfolders\n",
        "\n",
        "            if has_b1:\n",
        "                print(f\" Keeping subject with B1: {subject_path}\")\n",
        "                continue\n",
        "\n",
        "            elif has_n3:\n",
        "                print(f\" Subject with N3 only: {subject_path}\")\n",
        "                # Create NeedsPreprocessing folder if not exists\n",
        "                preprocess_path = os.path.join(subject_path, preprocess_folder)\n",
        "                os.makedirs(preprocess_path, exist_ok=True)\n",
        "\n",
        "                old_n3_path = os.path.join(subject_path, n3_folder)\n",
        "                new_n3_path = os.path.join(preprocess_path, n3_folder)\n",
        "\n",
        "                # Move N3 folder to NeedsPreprocessing\n",
        "                shutil.move(old_n3_path, new_n3_path)\n",
        "                print(f\" Moved {n3_folder} to {preprocess_folder}\")\n",
        "\n",
        "                # Delete any other irrelevant folders\n",
        "                for folder in subfolders:\n",
        "                    if folder != preprocess_folder and folder != n3_folder:\n",
        "                        folder_path = os.path.join(subject_path, folder)\n",
        "                        if os.path.isdir(folder_path):\n",
        "                            print(f\"üóëÔ∏è Deleting other folder: {folder_path}\")\n",
        "                            shutil.rmtree(folder_path)\n",
        "\n",
        "            else:\n",
        "                print(f\" No valid MPR found. Deleting subject: {subject_path}\")\n",
        "                shutil.rmtree(subject_path)\n",
        "\n",
        "# Run it:\n",
        "process_subjects_for_mpr([\n",
        "    r\"C:\\ADNI\\pMCI\",\n",
        "    r\"C:\\ADNI\\sMCI\"\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "rZSus60JAaMq",
        "outputId": "75ddc891-211e-4269-ddf3-8ad49ba31e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Processing root: C:\\ADNI\\pMCI\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\ADNI\\\\pMCI'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-fc09b83614ce>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Run it:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m process_subjects_for_mpr([\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;34mr\"C:\\ADNI\\pMCI\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;34mr\"C:\\ADNI\\sMCI\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-fc09b83614ce>\u001b[0m in \u001b[0;36mprocess_subjects_for_mpr\u001b[0;34m(root_dirs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mroot_dirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n Processing root: {root_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubject_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0msubject_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\ADNI\\\\pMCI'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "as we want to train and deploy a longitudinal deep learning model its important\n",
        "to orginaze the data so it would be consistent with the model structure\n",
        "\n",
        "so we turn such .nii file path from\n",
        "\"ADNI\\AD\\002_S_0619\\MPR-R__GradWarp__N3__Scaled\\2007-06-22_07_06_17.0\\I67871\\ADNI_002_S_0619_MR_MPR-R__GradWarp__N3__Scaled_Br_20070816100717385_S33969_I67871.nii\"\n",
        " into this\n",
        "\"ADNI_Organized\\AD\\002_S_0619\\timepoint_1\\ADNI_002_S_0619_MR_MPR-R__GradWarp__N3__Scaled_Br_20070816100717385_S33969_I67871.nii\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Root of original and destination folders\n",
        "input_groups = [\"pMCI\", \"sMCI\",\"AD\", \"CN\",\"NeedsBiasPreprocessingPmci\",\"NeedsBiasPreprocessingSmci\"]\n",
        "source_root = r\"C:\\ADNI\"\n",
        "destination_root = r\"C:\\ADNI_Sorted\"\n",
        "\n",
        "for group in input_groups:\n",
        "    group_path = os.path.join(source_root, group)\n",
        "    subjects = [s for s in os.listdir(group_path) if os.path.isdir(os.path.join(group_path, s))]\n",
        "\n",
        "    for subject in subjects:\n",
        "        subject_path = os.path.join(group_path, subject)\n",
        "\n",
        "        # Look for scan types like MPR__ or MPR-R__\n",
        "        for scan_type in os.listdir(subject_path):\n",
        "            scan_path = os.path.join(subject_path, scan_type)\n",
        "            if not os.path.isdir(scan_path):\n",
        "                continue\n",
        "\n",
        "            # Collect timepoint folders and sort by datetime\n",
        "            time_folders = []\n",
        "            for time_folder in os.listdir(scan_path):\n",
        "                try:\n",
        "                    time_obj = datetime.strptime(time_folder, \"%Y-%m-%d_%H_%M_%S.0\")\n",
        "                    full_path = os.path.join(scan_path, time_folder)\n",
        "                    time_folders.append((time_obj, full_path))\n",
        "                except ValueError:\n",
        "                    continue  # Skip malformed time folders\n",
        "\n",
        "            # Sort by date\n",
        "            time_folders.sort()\n",
        "\n",
        "            # Copy to new organized folder\n",
        "            for idx, (dt, full_path) in enumerate(time_folders, start=1):\n",
        "                new_folder = os.path.join(destination_root, group, subject, f\"timepoint_{idx}\")\n",
        "                os.makedirs(new_folder, exist_ok=True)\n",
        "\n",
        "                for root, _, files in os.walk(full_path):\n",
        "                    for file in files:\n",
        "                        src = os.path.join(root, file)\n",
        "                        dst = os.path.join(new_folder, file)\n",
        "                        shutil.copy2(src, dst)\n",
        "\n",
        "                print(f\" Copied: {subject}, {scan_type}, timepoint_{idx}\")\n",
        "\n",
        "print(\" All subjects organized by acquisition time.\")\n"
      ],
      "metadata": {
        "id": "GD-TpLadupf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p4bFU7Ji_pX4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}